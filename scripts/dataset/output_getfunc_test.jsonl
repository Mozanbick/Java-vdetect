{"idx": 1, "func": "InetSocketAddress createSocketAddr(String target){\n    return NetUtils.createSocketAddr(target);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 2, "func": "void addBlockPool(BPOfferService t){\n      if (nameNodeThreads.get(t.getNNSocketAddress()) == null) {\n        throw new IllegalArgumentException(\n            \"Unknown BPOfferService thread for namenode address:\"\n                + t.getNNSocketAddress());\n      }\n      if (t.getBlockPoolId() == null) {\n        throw new IllegalArgumentException(\"Null blockpool id\");\n      }\n      bpMapping.put(t.getBlockPoolId(), t);\n    }", "target": 0, "flaw_line_index": null}
{"idx": 3, "func": "BPOfferService[] getAllNamenodeThreads(){\n      BPOfferService[] bposArray = new BPOfferService[nameNodeThreads.values()\n          .size()];\n      return nameNodeThreads.values().toArray(bposArray);\n    }", "target": 0, "flaw_line_index": null}
{"idx": 4, "func": "BPOfferService get(InetSocketAddress addr){\n      return nameNodeThreads.get(addr);\n    }", "target": 0, "flaw_line_index": null}
{"idx": 5, "func": "BPOfferService get(String bpid){\n      return bpMapping.get(bpid);\n    }", "target": 0, "flaw_line_index": null}
{"idx": 6, "func": "void remove(BPOfferService t){\n      nameNodeThreads.remove(t.getNNSocketAddress());\n      bpMapping.remove(t.getBlockPoolId());\n    }", "target": 0, "flaw_line_index": null}
{"idx": 7, "func": "void shutDownAll(){\n      BPOfferService[] bposArray = this.getAllNamenodeThreads();\n      \n      for (BPOfferService bpos : bposArray) {\n        bpos.stop(); //interrupts the threads\n      }\n      //now join\n      for (BPOfferService bpos : bposArray) {\n        bpos.join();\n      }\n    }", "target": 0, "flaw_line_index": null}
{"idx": 8, "func": "void startAll(){\n      try {\n        UserGroupInformation.getLoginUser().doAs(\n            new PrivilegedExceptionAction<Object>() {\n              public Object run() throws Exception {\n                for (BPOfferService bpos : nameNodeThreads.values()) {\n                  bpos.start();\n                }\n                return null;\n              }\n            });\n      } catch (InterruptedException ex) {\n        IOException ioe = new IOException();\n        ioe.initCause(ex.getCause());\n        throw ioe;\n      }\n    }", "target": 0, "flaw_line_index": null}
{"idx": 9, "func": "void run(){\n        for(RecoveringBlock b : blocks) {\n          try {\n            logRecoverBlock(\"NameNode\", b.getBlock(), b.getLocations());\n            recoverBlock(b);\n          } catch (IOException e) {\n            LOG.warn(\"recoverBlocks FAILED: \" + b, e);\n          }\n        }\n      }", "target": 0, "flaw_line_index": null}
{"idx": 10, "func": "void joinAll(){\n      for (BPOfferService bpos: this.getAllNamenodeThreads()) {\n        bpos.join();\n      }\n    }", "target": 0, "flaw_line_index": null}
{"idx": 11, "func": "void refreshNamenodes(Configuration conf){\n    try {\n      blockPoolManager.refreshNamenodes(conf);\n    } catch (InterruptedException ex) {\n      IOException eio = new IOException();\n      eio.initCause(ex);\n      throw eio;\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 12, "func": "void setClusterId(String nsCid, String bpid){\n    if(clusterId != null && !clusterId.equals(nsCid)) {\n      throw new IOException (\"Cluster IDs not matched: dn cid=\" + clusterId \n          + \" but ns cid=\"+ nsCid + \"; bpid=\" + bpid);\n    }\n    // else\n    clusterId = nsCid;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 13, "func": "String getHostName(Configuration config){\n    // use configured nameserver & interface to get local hostname\n    String name = config.get(DFS_DATANODE_HOST_NAME_KEY);\n    if (name == null) {\n      name = DNS\n          .getDefaultHost(config.get(DFS_DATANODE_DNS_INTERFACE_KEY,\n              DFS_DATANODE_DNS_INTERFACE_DEFAULT), config.get(\n              DFS_DATANODE_DNS_NAMESERVER_KEY,\n              DFS_DATANODE_DNS_NAMESERVER_DEFAULT));\n    }\n    return name;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 14, "func": "void startInfoServer(Configuration conf){\n    // create a servlet to serve full-file content\n    InetSocketAddress infoSocAddr = DataNode.getInfoAddr(conf);\n    String infoHost = infoSocAddr.getHostName();\n    int tmpInfoPort = infoSocAddr.getPort();\n    this.infoServer = (secureResources == null) \n       ? new HttpServer(\"datanode\", infoHost, tmpInfoPort, tmpInfoPort == 0, \n           conf, new AccessControlList(conf.get(DFS_ADMIN, \" \")))\n       : new HttpServer(\"datanode\", infoHost, tmpInfoPort, tmpInfoPort == 0,\n           conf, new AccessControlList(conf.get(DFS_ADMIN, \" \")),\n           secureResources.getListener());\n    if(LOG.isDebugEnabled()) {\n      LOG.debug(\"Datanode listening on \" + infoHost + \":\" + tmpInfoPort);\n    }\n    if (conf.getBoolean(\"dfs.https.enable\", false)) {\n      boolean needClientAuth = conf.getBoolean(DFS_CLIENT_HTTPS_NEED_AUTH_KEY,\n                                               DFS_CLIENT_HTTPS_NEED_AUTH_DEFAULT);\n      InetSocketAddress secInfoSocAddr = NetUtils.createSocketAddr(conf.get(\n          \"dfs.datanode.https.address\", infoHost + \":\" + 0));\n      Configuration sslConf = new HdfsConfiguration(false);\n      sslConf.addResource(conf.get(\"dfs.https.server.keystore.resource\",\n          \"ssl-server.xml\"));\n      this.infoServer.addSslListener(secInfoSocAddr, sslConf, needClientAuth);\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"Datanode listening for SSL on \" + secInfoSocAddr);\n      }\n    }\n    this.infoServer.addInternalServlet(null, \"/streamFile/*\", StreamFile.class);\n    this.infoServer.addInternalServlet(null, \"/getFileChecksum/*\",\n        FileChecksumServlets.GetServlet.class);\n    \n    this.infoServer.setAttribute(\"datanode\", this);\n    this.infoServer.setAttribute(JspHelper.CURRENT_CONF, conf);\n    this.infoServer.addServlet(null, \"/blockScannerReport\", \n                               DataBlockScanner.Servlet.class);\n\n    if (WebHdfsFileSystem.isEnabled(conf, LOG)) {\n      infoServer.addJerseyResourcePackage(DatanodeWebHdfsMethods.class\n          .getPackage().getName() + \";\" + Param.class.getPackage().getName(),\n          WebHdfsFileSystem.PATH_PREFIX + \"/*\");\n    }\n    this.infoServer.start();\n  }", "target": 0, "flaw_line_index": null}
{"idx": 15, "func": "void startPlugins(Configuration conf){\n    plugins = conf.getInstances(DFS_DATANODE_PLUGINS_KEY, ServicePlugin.class);\n    for (ServicePlugin p: plugins) {\n      try {\n        p.start(this);\n        LOG.info(\"Started plug-in \" + p);\n      } catch (Throwable t) {\n        LOG.warn(\"ServicePlugin \" + p + \" could not be started\", t);\n      }\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 16, "func": "void initIpcServer(Configuration conf){\n    InetSocketAddress ipcAddr = NetUtils.createSocketAddr(\n        conf.get(\"dfs.datanode.ipc.address\"));\n    ipcServer = RPC.getServer(DataNode.class, this, ipcAddr.getHostName(),\n                              ipcAddr.getPort(), \n                              conf.getInt(DFS_DATANODE_HANDLER_COUNT_KEY, \n                                          DFS_DATANODE_HANDLER_COUNT_DEFAULT), \n                              false, conf, blockPoolTokenSecretManager);\n    // set service-level authorization security policy\n    if (conf.getBoolean(\n        CommonConfigurationKeys.HADOOP_SECURITY_AUTHORIZATION, false)) {\n      ipcServer.refreshServiceAcl(conf, new HDFSPolicyProvider());\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 17, "func": "void initPeriodicScanners(Configuration conf){\n    initDataBlockScanner(conf);\n    initDirectoryScanner(conf);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 18, "func": "void shutdownPeriodicScanners(){\n    shutdownDirectoryScanner();\n    shutdownDataBlockScanner();\n  }", "target": 0, "flaw_line_index": null}
{"idx": 19, "func": "void initDataBlockScanner(Configuration conf){\n    if (blockScanner != null) {\n      return;\n    }\n    String reason = null;\n    assert data != null;\n    if (conf.getInt(DFS_DATANODE_SCAN_PERIOD_HOURS_KEY,\n                    DFS_DATANODE_SCAN_PERIOD_HOURS_DEFAULT) < 0) {\n      reason = \"verification is turned off by configuration\";\n    } else if (\"SimulatedFSDataset\".equals(data.getClass().getSimpleName())) {\n      reason = \"verifcation is not supported by SimulatedFSDataset\";\n    } \n    if (reason == null) {\n      blockScanner = new DataBlockScanner(this, data, conf);\n      blockScanner.start();\n    } else {\n      LOG.info(\"Periodic Block Verification scan is disabled because \" +\n               reason + \".\");\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 20, "func": "void shutdownDataBlockScanner(){\n    if (blockScanner != null) {\n      blockScanner.shutdown();\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 21, "func": "void initDirectoryScanner(Configuration conf){\n    if (directoryScanner != null) {\n      return;\n    }\n    String reason = null;\n    if (conf.getInt(DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY, \n                    DFS_DATANODE_DIRECTORYSCAN_INTERVAL_DEFAULT) < 0) {\n      reason = \"verification is turned off by configuration\";\n    } else if (\"SimulatedFSDataset\".equals(data.getClass().getSimpleName())) {\n      reason = \"verifcation is not supported by SimulatedFSDataset\";\n    } \n    if (reason == null) {\n      directoryScanner = new DirectoryScanner(this, data, conf);\n      directoryScanner.start();\n    } else {\n      LOG.info(\"Periodic Directory Tree Verification scan is disabled because \" +\n               reason + \".\");\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 22, "func": "void shutdownDirectoryScanner(){\n    if (directoryScanner != null) {\n      directoryScanner.shutdown();\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 23, "func": "void initDataXceiver(Configuration conf){\n    InetSocketAddress socAddr = DataNode.getStreamingAddr(conf);\n\n    // find free port or use privileged port provided\n    ServerSocket ss;\n    if(secureResources == null) {\n      ss = (dnConf.socketWriteTimeout > 0) ? \n          ServerSocketChannel.open().socket() : new ServerSocket();\n          Server.bind(ss, socAddr, 0);\n    } else {\n      ss = secureResources.getStreamingSocket();\n    }\n    ss.setReceiveBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE); \n    // adjust machine name with the actual port\n    int tmpPort = ss.getLocalPort();\n    selfAddr = new InetSocketAddress(ss.getInetAddress().getHostAddress(),\n                                     tmpPort);\n    LOG.info(\"Opened info server at \" + tmpPort);\n      \n    this.threadGroup = new ThreadGroup(\"dataXceiverServer\");\n    this.dataXceiverServer = new Daemon(threadGroup, \n        new DataXceiverServer(ss, conf, this));\n    this.threadGroup.setDaemon(true); // auto destroy when empty\n  }", "target": 0, "flaw_line_index": null}
{"idx": 24, "func": "void notifyNamenodeReceivedBlock(ExtendedBlock block, String delHint){\n    BPOfferService bpos = blockPoolManager.get(block.getBlockPoolId());\n    if(bpos != null) {\n      bpos.notifyNamenodeReceivedBlock(block, delHint); \n    } else {\n      LOG.warn(\"Cannot find BPOfferService for reporting block received for bpid=\"\n          + block.getBlockPoolId());\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 25, "func": "void notifyNamenodeDeletedBlock(ExtendedBlock block){\n    BPOfferService bpos = blockPoolManager.get(block.getBlockPoolId());\n    if (bpos != null) {\n      bpos.notifyNamenodeDeletedBlock(block);\n    } else {\n      LOG.warn(\"Cannot find BPOfferService for reporting block deleted for bpid=\"\n          + block.getBlockPoolId());\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 26, "func": "void reportBadBlocks(ExtendedBlock block){\n    BPOfferService bpos = blockPoolManager.get(block.getBlockPoolId());\n    if(bpos == null || bpos.bpNamenode == null) {\n      throw new IOException(\"cannot locate OfferService thread for bp=\"+block.getBlockPoolId());\n    }\n    bpos.reportBadBlocks(block);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 27, "func": "void setHeartbeatsDisabledForTests(boolean heartbeatsDisabledForTests){\n    this.heartbeatsDisabledForTests = heartbeatsDisabledForTests;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 28, "func": "boolean areHeartbeatsDisabledForTests(){\n    return this.heartbeatsDisabledForTests;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 29, "func": "void startDataNode(Configuration conf, AbstractList<File> dataDirs, SecureResources resources){\n    if(UserGroupInformation.isSecurityEnabled() && resources == null)\n      throw new RuntimeException(\"Cannot start secure cluster without \" +\n      \"privileged resources.\");\n\n    // settings global for all BPs in the Data Node\n    this.secureResources = resources;\n    this.dataDirs = dataDirs;\n    this.conf = conf;\n    this.dnConf = new DNConf(conf);\n\n    storage = new DataStorage();\n    \n    // global DN settings\n    registerMXBean();\n    initDataXceiver(conf);\n    startInfoServer(conf);\n  \n    // BlockPoolTokenSecretManager is required to create ipc server.\n    this.blockPoolTokenSecretManager = new BlockPoolTokenSecretManager();\n    initIpcServer(conf);\n\n    metrics = DataNodeMetrics.create(conf, getMachineName());\n\n    blockPoolManager = new BlockPoolManager(conf);\n  }", "target": 1, "flaw_line_index": [21, 22, 23, 24, 25]}
{"idx": 30, "func": "DatanodeRegistration createBPRegistration(NamespaceInfo nsInfo){\n    DatanodeRegistration bpRegistration = createUnknownBPRegistration();\n    String blockPoolId = nsInfo.getBlockPoolID();\n    \n    bpRegistration.setStorageID(getStorageId());\n    StorageInfo storageInfo = storage.getBPStorage(blockPoolId);\n    if (storageInfo == null) {\n      // it's null in the case of SimulatedDataSet\n      bpRegistration.storageInfo.layoutVersion = HdfsConstants.LAYOUT_VERSION;\n      bpRegistration.setStorageInfo(nsInfo);\n    } else {\n      bpRegistration.setStorageInfo(storageInfo);\n    }\n    return bpRegistration;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 31, "func": "void bpRegistrationSucceeded(DatanodeRegistration bpRegistration, String blockPoolId){\n    hostName = bpRegistration.getHost();\n\n    if (storage.getStorageID().equals(\"\")) {\n      // This is a fresh datanode -- take the storage ID provided by the\n      // NN and persist it.\n      storage.setStorageID(bpRegistration.getStorageID());\n      storage.writeAll();\n      LOG.info(\"New storage id \" + bpRegistration.getStorageID()\n          + \" is assigned to data-node \" + bpRegistration.getName());\n    } else if(!storage.getStorageID().equals(bpRegistration.getStorageID())) {\n      throw new IOException(\"Inconsistent storage IDs. Name-node returned \"\n          + bpRegistration.getStorageID() \n          + \". Expecting \" + storage.getStorageID());\n    }\n    \n    registerBlockPoolWithSecretManager(bpRegistration, blockPoolId);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 32, "func": "void registerBlockPoolWithSecretManager(DatanodeRegistration bpRegistration, String blockPoolId){\n    ExportedBlockKeys keys = bpRegistration.exportedKeys;\n    isBlockTokenEnabled = keys.isBlockTokenEnabled();\n    // TODO should we check that all federated nns are either enabled or\n    // disabled?\n    if (!isBlockTokenEnabled) return;\n    \n    if (!blockPoolTokenSecretManager.isBlockPoolRegistered(blockPoolId)) {\n      long blockKeyUpdateInterval = keys.getKeyUpdateInterval();\n      long blockTokenLifetime = keys.getTokenLifetime();\n      LOG.info(\"Block token params received from NN: for block pool \" +\n          blockPoolId + \" keyUpdateInterval=\"\n          + blockKeyUpdateInterval / (60 * 1000)\n          + \" min(s), tokenLifetime=\" + blockTokenLifetime / (60 * 1000)\n          + \" min(s)\");\n      final BlockTokenSecretManager secretMgr = \n        new BlockTokenSecretManager(false, 0, blockTokenLifetime);\n      blockPoolTokenSecretManager.addBlockPool(blockPoolId, secretMgr);\n    }\n    \n    blockPoolTokenSecretManager.setKeys(blockPoolId,\n        bpRegistration.exportedKeys);\n    bpRegistration.exportedKeys = ExportedBlockKeys.DUMMY_KEYS;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 33, "func": "void shutdownBlockPool(BPOfferService bpos){\n    blockPoolManager.remove(bpos);\n\n    String bpId = bpos.getBlockPoolId();\n    if (blockScanner != null) {\n      blockScanner.removeBlockPool(bpId);\n    }\n  \n    if (data != null) { \n      data.shutdownBlockPool(bpId);\n    }\n\n    if (storage != null) {\n      storage.removeBlockPoolStorage(bpId);\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 34, "func": "void initBlockPool(BPOfferService bpos){\n    NamespaceInfo nsInfo = bpos.getNamespaceInfo();\n    if (nsInfo == null) {\n      throw new IOException(\"NamespaceInfo not found: Block pool \" + bpos\n          + \" should have retrieved namespace info before initBlockPool.\");\n    }\n    \n    // Register the new block pool with the BP manager.\n    blockPoolManager.addBlockPool(bpos);\n\n    setClusterId(nsInfo.clusterID, nsInfo.getBlockPoolID());\n    \n    // In the case that this is the first block pool to connect, initialize\n    // the dataset, block scanners, etc.\n    initStorage(nsInfo);\n    initPeriodicScanners(conf);\n    \n    data.addBlockPool(nsInfo.getBlockPoolID(), conf);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 35, "func": "DatanodeRegistration createUnknownBPRegistration(){\n    DatanodeRegistration reg = new DatanodeRegistration(\n        confHostName + \":\" + getPort());\n      \n    reg.setInfoPort(infoServer.getPort());\n    reg.setIpcPort(getIpcPort());\n    return reg;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 36, "func": "BPOfferService[] getAllBpOs(){\n    return blockPoolManager.getAllNamenodeThreads();\n  }", "target": 0, "flaw_line_index": null}
{"idx": 37, "func": "int getBpOsCount(){\n    return blockPoolManager.getAllNamenodeThreads().length;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 38, "func": "void initStorage(NamespaceInfo nsInfo){\n    final FSDatasetInterface.Factory factory\n        = FSDatasetInterface.Factory.getFactory(conf);\n    \n    if (!factory.isSimulated()) {\n      final StartupOption startOpt = getStartupOption(conf);\n      if (startOpt == null) {\n        throw new IOException(\"Startup option not set.\");\n      }\n      final String bpid = nsInfo.getBlockPoolID();\n      //read storage info, lock data dirs and transition fs state if necessary\n      storage.recoverTransitionRead(this, bpid, nsInfo, dataDirs, startOpt);\n      final StorageInfo bpStorage = storage.getBPStorage(bpid);\n      LOG.info(\"Setting up storage: nsid=\" + bpStorage.getNamespaceID()\n          + \";bpid=\" + bpid + \";lv=\" + storage.getLayoutVersion()\n          + \";nsInfo=\" + nsInfo);\n    }\n\n    synchronized(this)  {\n      if (data == null) {\n        data = factory.createFSDatasetInterface(this, storage, conf);\n      }\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 39, "func": "InetSocketAddress getInfoAddr(Configuration conf){\n    return NetUtils.createSocketAddr(conf.get(DFS_DATANODE_HTTP_ADDRESS_KEY,\n        DFS_DATANODE_HTTP_ADDRESS_DEFAULT));\n  }", "target": 0, "flaw_line_index": null}
{"idx": 40, "func": "void registerMXBean(){\n    MBeans.register(\"DataNode\", \"DataNodeInfo\", this);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 41, "func": "int getPort(){\n    return selfAddr.getPort();\n  }", "target": 0, "flaw_line_index": null}
{"idx": 42, "func": "String getStorageId(){\n    return storage.getStorageID();\n  }", "target": 0, "flaw_line_index": null}
{"idx": 43, "func": "String getMachineName(){\n    return hostName + \":\" + getPort();\n  }", "target": 0, "flaw_line_index": null}
{"idx": 44, "func": "int getIpcPort(){\n    return ipcServer.getListenerAddress().getPort();\n  }", "target": 0, "flaw_line_index": null}
{"idx": 45, "func": "DatanodeRegistration getDNRegistrationForBP(String bpid){\n    BPOfferService bpos = blockPoolManager.get(bpid);\n    if(bpos==null || bpos.bpRegistration==null) {\n      throw new IOException(\"cannot find BPOfferService for bpid=\"+bpid);\n    }\n    return bpos.bpRegistration;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 46, "func": "DatanodeRegistration getDNRegistrationByMachineName(String mName){\n    BPOfferService [] bposArray = blockPoolManager.getAllNamenodeThreads();\n    for (BPOfferService bpos : bposArray) {\n      if(bpos.bpRegistration.getName().equals(mName))\n        return bpos.bpRegistration;\n    }\n    return null;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 47, "func": "Socket newSocket(){\n    return (dnConf.socketWriteTimeout > 0) ? \n           SocketChannel.open().socket() : new Socket();                                   \n  }", "target": 0, "flaw_line_index": null}
{"idx": 48, "func": "InterDatanodeProtocol createInterDataNodeProtocolProxy(DatanodeID datanodeid, Configuration conf, int socketTimeout){\n    final InetSocketAddress addr = NetUtils.createSocketAddr(\n        datanodeid.getHost() + \":\" + datanodeid.getIpcPort());\n    if (InterDatanodeProtocol.LOG.isDebugEnabled()) {\n      InterDatanodeProtocol.LOG.debug(\"InterDatanodeProtocol addr=\" + addr);\n    }\n    UserGroupInformation loginUgi = UserGroupInformation.getLoginUser();\n    try {\n      return loginUgi\n          .doAs(new PrivilegedExceptionAction<InterDatanodeProtocol>() {\n            public InterDatanodeProtocol run() throws IOException {\n              return (InterDatanodeProtocol) RPC.getProxy(\n                  InterDatanodeProtocol.class, InterDatanodeProtocol.versionID,\n                  addr, UserGroupInformation.getCurrentUser(), conf,\n                  NetUtils.getDefaultSocketFactory(conf), socketTimeout);\n            }\n          });\n    } catch (InterruptedException ie) {\n      throw new IOException(ie.getMessage());\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 49, "func": "InetSocketAddress getNameNodeAddr(String bpid){\n    BPOfferService bp = blockPoolManager.get(bpid);\n    if (bp != null) {\n      return bp.getNNSocketAddress();\n    }\n    LOG.warn(\"No name node address found for block pool ID \" + bpid);\n    return null;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 50, "func": "InetSocketAddress getSelfAddr(){\n    return selfAddr;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 51, "func": "DataNodeMetrics getMetrics(){\n    return metrics;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 52, "func": "void setNewStorageID(DatanodeID dnId){\n    LOG.info(\"Datanode is \" + dnId);\n    dnId.storageID = createNewStorageId(dnId.getPort());\n  }", "target": 0, "flaw_line_index": null}
{"idx": 53, "func": "DatanodeProtocol connectToNN(InetSocketAddress nnAddr){\n    return (DatanodeProtocol)RPC.waitForProxy(DatanodeProtocol.class,\n          DatanodeProtocol.versionID, nnAddr, conf);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 54, "func": "String createNewStorageId(int port){\n    /* Return \n     * \"DS-randInt-ipaddr-currentTimeMillis\"\n     * It is considered extermely rare for all these numbers to match\n     * on a different machine accidentally for the following \n     * a) SecureRandom(INT_MAX) is pretty much random (1 in 2 billion), and\n     * b) Good chance ip address would be different, and\n     * c) Even on the same machine, Datanode is designed to use different ports.\n     * d) Good chance that these are started at different times.\n     * For a confict to occur all the 4 above have to match!.\n     * The format of this string can be changed anytime in future without\n     * affecting its functionality.\n     */\n    String ip = \"unknownIP\";\n    try {\n      ip = DNS.getDefaultIP(\"default\");\n    } catch (UnknownHostException ignored) {\n      LOG.warn(\"Could not find ip address of \\\"default\\\" inteface.\");\n    }\n    \n    int rand = DFSUtil.getSecureRandom().nextInt(Integer.MAX_VALUE);\n    return \"DS-\" + rand + \"-\" + ip + \"-\" + port + \"-\"\n        + System.currentTimeMillis();\n  }", "target": 0, "flaw_line_index": null}
{"idx": 55, "func": "void checkKerberosAuthMethod(String msg){\n    // User invoking the call must be same as the datanode user\n    if (!UserGroupInformation.isSecurityEnabled()) {\n      return;\n    }\n    if (UserGroupInformation.getCurrentUser().getAuthenticationMethod() != \n        AuthenticationMethod.KERBEROS) {\n      throw new AccessControlException(\"Error in \" + msg\n          + \"Only kerberos based authentication is allowed.\");\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 56, "func": "void checkBlockLocalPathAccess(){\n    checkKerberosAuthMethod(\"getBlockLocalPathInfo()\");\n    String currentUser = UserGroupInformation.getCurrentUser().getShortUserName();\n    if (!currentUser.equals(this.userWithLocalPathAccess)) {\n      throw new AccessControlException(\n          \"Can't continue with getBlockLocalPathInfo() \"\n              + \"authorization. The user \" + currentUser\n              + \" is not allowed to call getBlockLocalPathInfo\");\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 57, "func": "BlockLocalPathInfo getBlockLocalPathInfo(ExtendedBlock block, Token<BlockTokenIdentifier> token){\n    checkBlockLocalPathAccess();\n    checkBlockToken(block, token, BlockTokenSecretManager.AccessMode.READ);\n    BlockLocalPathInfo info = data.getBlockLocalPathInfo(block);\n    if (LOG.isDebugEnabled()) {\n      if (info != null) {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"getBlockLocalPathInfo successful block=\" + block\n              + \" blockfile \" + info.getBlockPath() + \" metafile \"\n              + info.getMetaPath());\n        }\n      } else {\n        if (LOG.isTraceEnabled()) {\n          LOG.trace(\"getBlockLocalPathInfo for block=\" + block\n              + \" returning null\");\n        }\n      }\n    }\n    metrics.incrBlocksGetLocalPathInfo();\n    return info;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 58, "func": "void checkBlockToken(ExtendedBlock block, Token<BlockTokenIdentifier> token, AccessMode accessMode){\n    if (isBlockTokenEnabled && UserGroupInformation.isSecurityEnabled()) {\n      BlockTokenIdentifier id = new BlockTokenIdentifier();\n      ByteArrayInputStream buf = new ByteArrayInputStream(token.getIdentifier());\n      DataInputStream in = new DataInputStream(buf);\n      id.readFields(in);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Got: \" + id.toString());\n      }\n      blockPoolTokenSecretManager.checkAccess(id, null, block, accessMode);\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 59, "func": "void shutdown(){\n    if (plugins != null) {\n      for (ServicePlugin p : plugins) {\n        try {\n          p.stop();\n          LOG.info(\"Stopped plug-in \" + p);\n        } catch (Throwable t) {\n          LOG.warn(\"ServicePlugin \" + p + \" could not be stopped\", t);\n        }\n      }\n    }\n    \n    this.shouldRun = false;\n    shutdownPeriodicScanners();\n    \n    if (infoServer != null) {\n      try {\n        infoServer.stop();\n      } catch (Exception e) {\n        LOG.warn(\"Exception shutting down DataNode\", e);\n      }\n    }\n    if (ipcServer != null) {\n      ipcServer.stop();\n    }\n    \n    if (dataXceiverServer != null) {\n      ((DataXceiverServer) this.dataXceiverServer.getRunnable()).kill();\n      this.dataXceiverServer.interrupt();\n\n      // wait for all data receiver threads to exit\n      if (this.threadGroup != null) {\n        int sleepMs = 2;\n        while (true) {\n          this.threadGroup.interrupt();\n          LOG.info(\"Waiting for threadgroup to exit, active threads is \" +\n                   this.threadGroup.activeCount());\n          if (this.threadGroup.activeCount() == 0) {\n            break;\n          }\n          try {\n            Thread.sleep(sleepMs);\n          } catch (InterruptedException e) {}\n          sleepMs = sleepMs * 3 / 2; // exponential backoff\n          if (sleepMs > 1000) {\n            sleepMs = 1000;\n          }\n        }\n      }\n      // wait for dataXceiveServer to terminate\n      try {\n        this.dataXceiverServer.join();\n      } catch (InterruptedException ie) {\n      }\n    }\n    \n    if(blockPoolManager != null) {\n      try {\n        this.blockPoolManager.shutDownAll();\n      } catch (InterruptedException ie) {\n        LOG.warn(\"Received exception in BlockPoolManager#shutDownAll: \", ie);\n      }\n    }\n    \n    if (storage != null) {\n      try {\n        this.storage.unlockAll();\n      } catch (IOException ie) {\n        LOG.warn(\"Exception when unlocking storage: \" + ie, ie);\n      }\n    }\n    if (data != null) {\n      data.shutdown();\n    }\n    if (metrics != null) {\n      metrics.shutdown();\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 60, "func": "void checkDiskError(Exception e){\n    \n    LOG.warn(\"checkDiskError: exception: \", e);\n    if (e instanceof SocketException || e instanceof SocketTimeoutException\n    \t  || e instanceof ClosedByInterruptException \n    \t  || e.getMessage().startsWith(\"An established connection was aborted\")\n    \t  || e.getMessage().startsWith(\"Broken pipe\")\n    \t  || e.getMessage().startsWith(\"Connection reset\")\n    \t  || e.getMessage().contains(\"java.nio.channels.SocketChannel\")) {\n      LOG.info(\"Not checking disk as checkDiskError was called on a network\" +\n      \t\t\" related exception\");\t\n      return;\n    }\n    if (e.getMessage() != null &&\n        e.getMessage().startsWith(\"No space left on device\")) {\n      throw new DiskOutOfSpaceException(\"No space left on device\");\n    } else {\n      checkDiskError();\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 61, "func": "void checkDiskError(){\n    try {\n      data.checkDataDir();\n    } catch (DiskErrorException de) {\n      handleDiskError(de.getMessage());\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 62, "func": "void handleDiskError(String errMsgr){\n    final boolean hasEnoughResources = data.hasEnoughResource();\n    LOG.warn(\"DataNode.handleDiskError: Keep Running: \" + hasEnoughResources);\n    \n    // If we have enough active valid volumes then we do not want to \n    // shutdown the DN completely.\n    int dpError = hasEnoughResources ? DatanodeProtocol.DISK_ERROR  \n                                     : DatanodeProtocol.FATAL_DISK_ERROR;  \n    metrics.incrVolumeFailures();\n\n    //inform NameNodes\n    for(BPOfferService bpos: blockPoolManager.getAllNamenodeThreads()) {\n      DatanodeProtocol nn = bpos.bpNamenode;\n      try {\n        nn.errorReport(bpos.bpRegistration, dpError, errMsgr);\n      } catch(IOException e) {\n        LOG.warn(\"Error reporting disk failure to NameNode\", e);\n      }\n    }\n    \n    if(hasEnoughResources) {\n      scheduleAllBlockReport(0);\n      return; // do not shutdown\n    }\n    \n    LOG.warn(\"DataNode is shutting down: \" + errMsgr);\n    shouldRun = false;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 63, "func": "int getXceiverCount(){\n    return threadGroup == null ? 0 : threadGroup.activeCount();\n  }", "target": 0, "flaw_line_index": null}
{"idx": 64, "func": "UpgradeManagerDatanode getUpgradeManagerDatanode(String bpid){\n    BPOfferService bpos = blockPoolManager.get(bpid);\n    if(bpos==null) {\n      return null;\n    }\n    return bpos.getUpgradeManager();\n  }", "target": 0, "flaw_line_index": null}
{"idx": 65, "func": "void transferBlock(ExtendedBlock block, DatanodeInfo xferTargets){\n    DatanodeProtocol nn = getBPNamenode(block.getBlockPoolId());\n    DatanodeRegistration bpReg = getDNRegistrationForBP(block.getBlockPoolId());\n    \n    if (!data.isValidBlock(block)) {\n      // block does not exist or is under-construction\n      String errStr = \"Can't send invalid block \" + block;\n      LOG.info(errStr);\n      nn.errorReport(bpReg, DatanodeProtocol.INVALID_BLOCK, errStr);\n      return;\n    }\n\n    // Check if NN recorded length matches on-disk length \n    long onDiskLength = data.getLength(block);\n    if (block.getNumBytes() > onDiskLength) {\n      // Shorter on-disk len indicates corruption so report NN the corrupt block\n      nn.reportBadBlocks(new LocatedBlock[]{\n          new LocatedBlock(block, new DatanodeInfo[] {\n              new DatanodeInfo(bpReg)})});\n      LOG.warn(\"Can't replicate block \" + block\n          + \" because on-disk length \" + onDiskLength \n          + \" is shorter than NameNode recorded length \" + block.getNumBytes());\n      return;\n    }\n    \n    int numTargets = xferTargets.length;\n    if (numTargets > 0) {\n      if (LOG.isInfoEnabled()) {\n        StringBuilder xfersBuilder = new StringBuilder();\n        for (int i = 0; i < numTargets; i++) {\n          xfersBuilder.append(xferTargets[i].getName());\n          xfersBuilder.append(\" \");\n        }\n        LOG.info(bpReg + \" Starting thread to transfer block \" + \n                 block + \" to \" + xfersBuilder);                       \n      }\n\n      new Daemon(new DataTransfer(xferTargets, block,\n          BlockConstructionStage.PIPELINE_SETUP_CREATE, \"\")).start();\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 66, "func": "void transferBlocks(String poolId, Block blocks, DatanodeInfo xferTargets){\n    for (int i = 0; i < blocks.length; i++) {\n      try {\n        transferBlock(new ExtendedBlock(poolId, blocks[i]), xferTargets[i]);\n      } catch (IOException ie) {\n        LOG.warn(\"Failed to transfer block \" + blocks[i], ie);\n      }\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 67, "func": "void closeBlock(ExtendedBlock block, String delHint){\n    metrics.incrBlocksWritten();\n    BPOfferService bpos = blockPoolManager.get(block.getBlockPoolId());\n    if(bpos != null) {\n      bpos.notifyNamenodeReceivedBlock(block, delHint);\n    } else {\n      LOG.warn(\"Cannot find BPOfferService for reporting block received for bpid=\"\n          + block.getBlockPoolId());\n    }\n    if (blockScanner != null) {\n      blockScanner.addBlock(block);\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 68, "func": "void runDatanodeDaemon(){\n    blockPoolManager.startAll();\n\n    // start dataXceiveServer\n    dataXceiverServer.start();\n    ipcServer.start();\n    startPlugins(conf);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 69, "func": "boolean isDatanodeUp(){\n    for (BPOfferService bp : blockPoolManager.getAllNamenodeThreads()) {\n      if (bp.isAlive()) {\n        return true;\n      }\n    }\n    return false;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 70, "func": "DataNode instantiateDataNode(String args, Configuration conf){\n    return instantiateDataNode(args, conf, null);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 71, "func": "DataNode instantiateDataNode(String args, Configuration conf, SecureResources resources){\n    if (conf == null)\n      conf = new HdfsConfiguration();\n    \n    if (args != null) {\n      // parse generic hadoop options\n      GenericOptionsParser hParser = new GenericOptionsParser(conf, args);\n      args = hParser.getRemainingArgs();\n    }\n    \n    if (!parseArguments(args, conf)) {\n      printUsage();\n      return null;\n    }\n    if (conf.get(\"dfs.network.script\") != null) {\n      LOG.error(\"This configuration for rack identification is not supported\" +\n          \" anymore. RackID resolution is handled by the NameNode.\");\n      System.exit(-1);\n    }\n    Collection<URI> dataDirs = getStorageDirs(conf);\n    UserGroupInformation.setConfiguration(conf);\n    SecurityUtil.login(conf, DFS_DATANODE_KEYTAB_FILE_KEY,\n        DFS_DATANODE_USER_NAME_KEY);\n    return makeInstance(dataDirs, conf, resources);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 72, "func": "Collection<URI> getStorageDirs(Configuration conf){\n    Collection<String> dirNames =\n      conf.getTrimmedStringCollection(DFS_DATANODE_DATA_DIR_KEY);\n    return Util.stringCollectionAsURIs(dirNames);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 73, "func": "DataNode createDataNode(String args, Configuration conf){\n    return createDataNode(args, conf, null);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 74, "func": "DataNode createDataNode(String args, Configuration conf, SecureResources resources){\n    DataNode dn = instantiateDataNode(args, conf, resources);\n    if (dn != null) {\n      dn.runDatanodeDaemon();\n    }\n    return dn;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 75, "func": "void join(){\n    while (shouldRun) {\n      try {\n        blockPoolManager.joinAll();\n        if (blockPoolManager.getAllNamenodeThreads() != null\n            && blockPoolManager.getAllNamenodeThreads().length == 0) {\n          shouldRun = false;\n        }\n        Thread.sleep(2000);\n      } catch (InterruptedException ex) {\n        LOG.warn(\"Received exception in Datanode#join: \" + ex);\n      }\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 76, "func": "DataNode makeInstance(Collection<URI> dataDirs, Configuration conf, SecureResources resources){\n    LocalFileSystem localFS = FileSystem.getLocal(conf);\n    FsPermission permission = new FsPermission(\n        conf.get(DFS_DATANODE_DATA_DIR_PERMISSION_KEY,\n                 DFS_DATANODE_DATA_DIR_PERMISSION_DEFAULT));\n    ArrayList<File> dirs = getDataDirsFromURIs(dataDirs, localFS, permission);\n    DefaultMetricsSystem.initialize(\"DataNode\");\n\n    assert dirs.size() > 0 : \"number of data directories should be > 0\";\n    return new DataNode(conf, dirs, resources);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 77, "func": "ArrayList<File> getDataDirsFromURIs(Collection<URI> dataDirs, LocalFileSystem localFS, FsPermission permission){\n    ArrayList<File> dirs = new ArrayList<File>();\n    StringBuilder invalidDirs = new StringBuilder();\n    for (URI dirURI : dataDirs) {\n      if (!\"file\".equalsIgnoreCase(dirURI.getScheme())) {\n        LOG.warn(\"Unsupported URI schema in \" + dirURI + \". Ignoring ...\");\n        invalidDirs.append(\"\\\"\").append(dirURI).append(\"\\\" \");\n        continue;\n      }\n      // drop any (illegal) authority in the URI for backwards compatibility\n      File dir = new File(dirURI.getPath());\n      try {\n        DiskChecker.checkDir(localFS, new Path(dir.toURI()), permission);\n        dirs.add(dir);\n      } catch (IOException ioe) {\n        LOG.warn(\"Invalid \" + DFS_DATANODE_DATA_DIR_KEY + \" \"\n            + dir + \" : \", ioe);\n        invalidDirs.append(\"\\\"\").append(dir.getCanonicalPath()).append(\"\\\" \");\n      }\n    }\n    if (dirs.size() == 0) {\n      throw new IOException(\"All directories in \"\n          + DFS_DATANODE_DATA_DIR_KEY + \" are invalid: \"\n          + invalidDirs);\n    }\n    return dirs;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 78, "func": "String toString(){\n      return \"block:\" + rInfo + \" node:\" + id;\n    }", "target": 0, "flaw_line_index": null}
{"idx": 79, "func": "void printUsage(){\n    System.err.println(\"Usage: java DataNode\");\n    System.err.println(\"           [-rollback]\");\n  }", "target": 0, "flaw_line_index": null}
{"idx": 80, "func": "boolean parseArguments(String args, Configuration conf){\n    int argsLen = (args == null) ? 0 : args.length;\n    StartupOption startOpt = StartupOption.REGULAR;\n    for(int i=0; i < argsLen; i++) {\n      String cmd = args[i];\n      if (\"-r\".equalsIgnoreCase(cmd) || \"--rack\".equalsIgnoreCase(cmd)) {\n        LOG.error(\"-r, --rack arguments are not supported anymore. RackID \" +\n            \"resolution is handled by the NameNode.\");\n        terminate(1);\n      } else if (\"-rollback\".equalsIgnoreCase(cmd)) {\n        startOpt = StartupOption.ROLLBACK;\n      } else if (\"-regular\".equalsIgnoreCase(cmd)) {\n        startOpt = StartupOption.REGULAR;\n      } else\n        return false;\n    }\n    setStartupOption(conf, startOpt);\n    return true;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 81, "func": "void setStartupOption(Configuration conf, StartupOption opt){\n    conf.set(DFS_DATANODE_STARTUP_KEY, opt.toString());\n  }", "target": 0, "flaw_line_index": null}
{"idx": 82, "func": "StartupOption getStartupOption(Configuration conf){\n    return StartupOption.valueOf(conf.get(DFS_DATANODE_STARTUP_KEY,\n                                          StartupOption.REGULAR.toString()));\n  }", "target": 0, "flaw_line_index": null}
{"idx": 83, "func": "void scheduleAllBlockReport(long delay){\n    for(BPOfferService bpos : blockPoolManager.getAllNamenodeThreads()) {\n      bpos.scheduleBlockReport(delay);\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 84, "func": "FSDatasetInterface getFSDataset(){\n    return data;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 85, "func": "void secureMain(String args, SecureResources resources){\n    try {\n      StringUtils.startupShutdownMessage(DataNode.class, args, LOG);\n      DataNode datanode = createDataNode(args, null, resources);\n      if (datanode != null)\n        datanode.join();\n    } catch (Throwable e) {\n      LOG.fatal(\"Exception in secureMain\", e);\n      terminate(1);\n    } finally {\n      // We need to terminate the process here because either shutdown was called\n      // or some disk related conditions like volumes tolerated or volumes required\n      // condition was not met. Also, In secure mode, control will go to Jsvc\n      // and Datanode process hangs if it does not exit.\n      LOG.warn(\"Exiting Datanode\");\n      terminate(0);\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 86, "func": "void main(String args){\n    secureMain(args, null);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 87, "func": "Daemon recoverBlocks(Collection<RecoveringBlock> blocks){\n    Daemon d = new Daemon(threadGroup, new Runnable() {\n      /** Recover a list of blocks. It is run by the primary datanode. */\n      public void run() {\n        for(RecoveringBlock b : blocks) {\n          try {\n            logRecoverBlock(\"NameNode\", b.getBlock(), b.getLocations());\n            recoverBlock(b);\n          } catch (IOException e) {\n            LOG.warn(\"recoverBlocks FAILED: \" + b, e);\n          }\n        }\n      }\n    });\n    d.start();\n    return d;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 88, "func": "ReplicaRecoveryInfo initReplicaRecovery(RecoveringBlock rBlock){\n    return data.initReplicaRecovery(rBlock);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 89, "func": "ReplicaRecoveryInfo callInitReplicaRecovery(InterDatanodeProtocol datanode, RecoveringBlock rBlock){\n    try {\n      return datanode.initReplicaRecovery(rBlock);\n    } catch(RemoteException re) {\n      throw re.unwrapRemoteException();\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 90, "func": "ExtendedBlock updateReplicaUnderRecovery(ExtendedBlock oldBlock, long recoveryId, long newLength){\n    ReplicaInfo r = data.updateReplicaUnderRecovery(oldBlock,\n        recoveryId, newLength);\n    return new ExtendedBlock(oldBlock.getBlockPoolId(), r);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 91, "func": "long getProtocolVersion(String protocol, long clientVersion){\n    if (protocol.equals(InterDatanodeProtocol.class.getName())) {\n      return InterDatanodeProtocol.versionID; \n    } else if (protocol.equals(ClientDatanodeProtocol.class.getName())) {\n      return ClientDatanodeProtocol.versionID; \n    }\n    throw new IOException(\"Unknown protocol to \" + getClass().getSimpleName()\n        + \": \" + protocol);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 92, "func": "ProtocolSignature getProtocolSignature(String protocol, long clientVersion, int clientMethodsHash){\n    return ProtocolSignature.getProtocolSignature(\n        this, protocol, clientVersion, clientMethodsHash);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 93, "func": "void recoverBlock(RecoveringBlock rBlock){\n    ExtendedBlock block = rBlock.getBlock();\n    String blookPoolId = block.getBlockPoolId();\n    DatanodeInfo[] targets = rBlock.getLocations();\n    DatanodeID[] datanodeids = (DatanodeID[])targets;\n    List<BlockRecord> syncList = new ArrayList<BlockRecord>(datanodeids.length);\n    int errorCount = 0;\n\n    //check generation stamps\n    for(DatanodeID id : datanodeids) {\n      try {\n        BPOfferService bpos = blockPoolManager.get(blookPoolId);\n        DatanodeRegistration bpReg = bpos.bpRegistration;\n        InterDatanodeProtocol datanode = bpReg.equals(id)?\n            this: DataNode.createInterDataNodeProtocolProxy(id, getConf(),\n                dnConf.socketTimeout);\n        ReplicaRecoveryInfo info = callInitReplicaRecovery(datanode, rBlock);\n        if (info != null &&\n            info.getGenerationStamp() >= block.getGenerationStamp() &&\n            info.getNumBytes() > 0) {\n          syncList.add(new BlockRecord(id, datanode, info));\n        }\n      } catch (RecoveryInProgressException ripE) {\n        InterDatanodeProtocol.LOG.warn(\n            \"Recovery for replica \" + block + \" on data-node \" + id\n            + \" is already in progress. Recovery id = \"\n            + rBlock.getNewGenerationStamp() + \" is aborted.\", ripE);\n        return;\n      } catch (IOException e) {\n        ++errorCount;\n        InterDatanodeProtocol.LOG.warn(\n            \"Failed to obtain replica info for block (=\" + block \n            + \") from datanode (=\" + id + \")\", e);\n      }\n    }\n\n    if (errorCount == datanodeids.length) {\n      throw new IOException(\"All datanodes failed: block=\" + block\n          + \", datanodeids=\" + Arrays.asList(datanodeids));\n    }\n\n    syncBlock(rBlock, syncList);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 94, "func": "DatanodeProtocol getBPNamenode(String bpid){\n    BPOfferService bpos = blockPoolManager.get(bpid);\n    if (bpos == null) {\n      throw new IOException(\"No block pool offer service for bpid=\" + bpid);\n    } else if (bpos.bpNamenode == null) {\n      throw new IOException(\"cannot find a namenode proxy for bpid=\" + bpid);\n    }\n    return bpos.bpNamenode;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 95, "func": "void syncBlock(RecoveringBlock rBlock, List<BlockRecord> syncList){\n    ExtendedBlock block = rBlock.getBlock();\n    DatanodeProtocol nn = getBPNamenode(block.getBlockPoolId());\n    \n    long recoveryId = rBlock.getNewGenerationStamp();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"block=\" + block + \", (length=\" + block.getNumBytes()\n          + \"), syncList=\" + syncList);\n    }\n\n    // syncList.isEmpty() means that all data-nodes do not have the block\n    // or their replicas have 0 length.\n    // The block can be deleted.\n    if (syncList.isEmpty()) {\n      nn.commitBlockSynchronization(block, recoveryId, 0,\n          true, true, DatanodeID.EMPTY_ARRAY);\n      return;\n    }\n\n    // Calculate the best available replica state.\n    ReplicaState bestState = ReplicaState.RWR;\n    long finalizedLength = -1;\n    for(BlockRecord r : syncList) {\n      assert r.rInfo.getNumBytes() > 0 : \"zero length replica\";\n      ReplicaState rState = r.rInfo.getOriginalReplicaState(); \n      if(rState.getValue() < bestState.getValue())\n        bestState = rState;\n      if(rState == ReplicaState.FINALIZED) {\n        if(finalizedLength > 0 && finalizedLength != r.rInfo.getNumBytes())\n          throw new IOException(\"Inconsistent size of finalized replicas. \" +\n              \"Replica \" + r.rInfo + \" expected size: \" + finalizedLength);\n        finalizedLength = r.rInfo.getNumBytes();\n      }\n    }\n\n    // Calculate list of nodes that will participate in the recovery\n    // and the new block size\n    List<BlockRecord> participatingList = new ArrayList<BlockRecord>();\n    final ExtendedBlock newBlock = new ExtendedBlock(block.getBlockPoolId(), block\n        .getBlockId(), -1, recoveryId);\n    switch(bestState) {\n    case FINALIZED:\n      assert finalizedLength > 0 : \"finalizedLength is not positive\";\n      for(BlockRecord r : syncList) {\n        ReplicaState rState = r.rInfo.getOriginalReplicaState();\n        if(rState == ReplicaState.FINALIZED ||\n           rState == ReplicaState.RBW &&\n                      r.rInfo.getNumBytes() == finalizedLength)\n          participatingList.add(r);\n      }\n      newBlock.setNumBytes(finalizedLength);\n      break;\n    case RBW:\n    case RWR:\n      long minLength = Long.MAX_VALUE;\n      for(BlockRecord r : syncList) {\n        ReplicaState rState = r.rInfo.getOriginalReplicaState();\n        if(rState == bestState) {\n          minLength = Math.min(minLength, r.rInfo.getNumBytes());\n          participatingList.add(r);\n        }\n      }\n      newBlock.setNumBytes(minLength);\n      break;\n    case RUR:\n    case TEMPORARY:\n      assert false : \"bad replica state: \" + bestState;\n    }\n\n    List<DatanodeID> failedList = new ArrayList<DatanodeID>();\n    List<DatanodeID> successList = new ArrayList<DatanodeID>();\n    for(BlockRecord r : participatingList) {\n      try {\n        ExtendedBlock reply = r.datanode.updateReplicaUnderRecovery(\n            new ExtendedBlock(newBlock.getBlockPoolId(), r.rInfo), recoveryId,\n            newBlock.getNumBytes());\n        assert reply.equals(newBlock) &&\n               reply.getNumBytes() == newBlock.getNumBytes() :\n          \"Updated replica must be the same as the new block.\";\n        successList.add(r.id);\n      } catch (IOException e) {\n        InterDatanodeProtocol.LOG.warn(\"Failed to updateBlock (newblock=\"\n            + newBlock + \", datanode=\" + r.id + \")\", e);\n        failedList.add(r.id);\n      }\n    }\n\n    // If any of the data-nodes failed, the recovery fails, because\n    // we never know the actual state of the replica on failed data-nodes.\n    // The recovery should be started over.\n    if(!failedList.isEmpty()) {\n      StringBuilder b = new StringBuilder();\n      for(DatanodeID id : failedList) {\n        b.append(\"\\n  \" + id);\n      }\n      throw new IOException(\"Cannot recover \" + block + \", the following \"\n          + failedList.size() + \" data-nodes failed {\" + b + \"\\n}\");\n    }\n\n    // Notify the name-node about successfully recovered replicas.\n    DatanodeID[] nlist = successList.toArray(new DatanodeID[successList.size()]);\n    nn.commitBlockSynchronization(block,\n        newBlock.getGenerationStamp(), newBlock.getNumBytes(), true, false,\n        nlist);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 96, "func": "void logRecoverBlock(String who, ExtendedBlock block, DatanodeID[] targets){\n    StringBuilder msg = new StringBuilder(targets[0].getName());\n    for (int i = 1; i < targets.length; i++) {\n      msg.append(\", \" + targets[i].getName());\n    }\n    LOG.info(who + \" calls recoverBlock(block=\" + block\n        + \", targets=[\" + msg + \"])\");\n  }", "target": 0, "flaw_line_index": null}
{"idx": 97, "func": "long getReplicaVisibleLength(ExtendedBlock block){\n    checkWriteAccess(block);\n    return data.getReplicaVisibleLength(block);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 98, "func": "void checkWriteAccess(ExtendedBlock block){\n    if (isBlockTokenEnabled) {\n      Set<TokenIdentifier> tokenIds = UserGroupInformation.getCurrentUser()\n          .getTokenIdentifiers();\n      if (tokenIds.size() != 1) {\n        throw new IOException(\"Can't continue since none or more than one \"\n            + \"BlockTokenIdentifier is found.\");\n      }\n      for (TokenIdentifier tokenId : tokenIds) {\n        BlockTokenIdentifier id = (BlockTokenIdentifier) tokenId;\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Got: \" + id.toString());\n        }\n        blockPoolTokenSecretManager.checkAccess(id, null, block,\n            BlockTokenSecretManager.AccessMode.READ);\n      }\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 99, "func": "void transferReplicaForPipelineRecovery(ExtendedBlock b, DatanodeInfo[] targets, String client){\n    final long storedGS;\n    final long visible;\n    final BlockConstructionStage stage;\n\n    //get replica information\n    synchronized(data) {\n      Block storedBlock = data.getStoredBlock(b.getBlockPoolId(),\n          b.getBlockId());\n      if (null == storedBlock) {\n        throw new IOException(b + \" not found in datanode.\");\n      }\n      storedGS = storedBlock.getGenerationStamp();\n      if (storedGS < b.getGenerationStamp()) {\n        throw new IOException(storedGS\n            + \" = storedGS < b.getGenerationStamp(), b=\" + b);\n      }\n      // Update the genstamp with storedGS\n      b.setGenerationStamp(storedGS);\n      if (data.isValidRbw(b)) {\n        stage = BlockConstructionStage.TRANSFER_RBW;\n      } else if (data.isValidBlock(b)) {\n        stage = BlockConstructionStage.TRANSFER_FINALIZED;\n      } else {\n        final String r = data.getReplicaString(b.getBlockPoolId(), b.getBlockId());\n        throw new IOException(b + \" is neither a RBW nor a Finalized, r=\" + r);\n      }\n      visible = data.getReplicaVisibleLength(b);\n    }\n    //set visible length\n    b.setNumBytes(visible);\n\n    if (targets.length > 0) {\n      new DataTransfer(targets, b, stage, client).run();\n    }\n  }", "target": 0, "flaw_line_index": null}
{"idx": 100, "func": "void finalizeUpgradeForPool(String blockPoolId){\n    storage.finalizeUpgrade(blockPoolId);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 101, "func": "InetSocketAddress getStreamingAddr(Configuration conf){\n    return NetUtils.createSocketAddr(\n        conf.get(DFS_DATANODE_ADDRESS_KEY, DFS_DATANODE_ADDRESS_DEFAULT));\n  }", "target": 0, "flaw_line_index": null}
{"idx": 102, "func": "String getVersion(){\n    return VersionInfo.getVersion();\n  }", "target": 0, "flaw_line_index": null}
{"idx": 103, "func": "String getRpcPort(){\n    InetSocketAddress ipcAddr = NetUtils.createSocketAddr(\n        this.getConf().get(DFS_DATANODE_IPC_ADDRESS_KEY));\n    return Integer.toString(ipcAddr.getPort());\n  }", "target": 0, "flaw_line_index": null}
{"idx": 104, "func": "String getHttpPort(){\n    return this.getConf().get(\"dfs.datanode.info.port\");\n  }", "target": 0, "flaw_line_index": null}
{"idx": 105, "func": "int getInfoPort(){\n    return this.infoServer.getPort();\n  }", "target": 0, "flaw_line_index": null}
{"idx": 106, "func": "String getNamenodeAddresses(){\n    final Map<String, String> info = new HashMap<String, String>();\n    for (BPOfferService bpos : blockPoolManager.getAllNamenodeThreads()) {\n      if (bpos != null && bpos.bpThread != null) {\n        info.put(bpos.getNNSocketAddress().getHostName(), bpos.getBlockPoolId());\n      }\n    }\n    return JSON.toString(info);\n  }", "target": 0, "flaw_line_index": null}
{"idx": 107, "func": "String getVolumeInfo(){\n    return JSON.toString(data.getVolumeInfoMap());\n  }", "target": 0, "flaw_line_index": null}
{"idx": 108, "func": "String getClusterId(){\n    return clusterId;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 109, "func": "void refreshNamenodes(){\n    conf = new Configuration();\n    refreshNamenodes(conf);\n  }", "target": 1, "flaw_line_index": [2]}
{"idx": 110, "func": "void deleteBlockPool(String blockPoolId, boolean force){\n    LOG.info(\"deleteBlockPool command received for block pool \" + blockPoolId\n        + \", force=\" + force);\n    if (blockPoolManager.get(blockPoolId) != null) {\n      LOG.warn(\"The block pool \"+blockPoolId+\n          \" is still running, cannot be deleted.\");\n      throw new IOException(\n          \"The block pool is still running. First do a refreshNamenodes to \" +\n          \"shutdown the block pool service\");\n    }\n   \n    data.deleteBlockPool(blockPoolId, force);\n  }", "target": 1, "flaw_line_index": [2]}
{"idx": 111, "func": "boolean isBPServiceAlive(InetSocketAddress addr){\n    BPOfferService bp = blockPoolManager.get(addr);\n    return bp != null ? bp.isAlive() : false;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 112, "func": "boolean isBPServiceAlive(String bpid){\n    BPOfferService bp = blockPoolManager.get(bpid);\n    return bp != null ? bp.isAlive() : false;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 113, "func": "boolean isDatanodeFullyStarted(){\n    for (BPOfferService bp : blockPoolManager.getAllNamenodeThreads()) {\n      if (!bp.isInitialized() || !bp.isAlive()) {\n        return false;\n      }\n    }\n    return true;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 114, "func": "DatanodeID getDatanodeId(){\n    return new DatanodeID(getMachineName(), getStorageId(),\n        infoServer.getPort(), getIpcPort());\n  }", "target": 0, "flaw_line_index": null}
{"idx": 115, "func": "Long getBalancerBandwidth(){\n    DataXceiverServer dxcs =\n                       (DataXceiverServer) this.dataXceiverServer.getRunnable();\n    return dxcs.balanceThrottler.getBandwidth();\n  }", "target": 0, "flaw_line_index": null}
{"idx": 116, "func": "DNConf getDnConf(){\n    return dnConf;\n  }", "target": 0, "flaw_line_index": null}
{"idx": 117, "func": "boolean shouldRun(){\n    return shouldRun;\n  }", "target": 0, "flaw_line_index": null}
